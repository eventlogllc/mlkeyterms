    "what": [
      "A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.",
      "Activation functions add nonlinearity to neural networks. The more nonlinear our decision function, the more complex decisions it can make.",
       "[英] [related] [A function], [(for example, ReLU or sigmoid)], [takes in the weighted sum of all of the inputs], [from the previous layer], [and then generates and passes an output value], [(typically nonlinear)], [to the next layer.]",
      "[和] [関数], [（たとえば、ReLUまたはシグモイド）], [すべての入力の加重和を取ります], [前のレイヤーから], [そして出力値を生成して渡します], [（通常は非線形）], [次のレイヤーへ]",	    
      "[漢] [相關], [一個函數], [（例如，ReLU 或 sigmoid）], [獲取所有輸入的加權和], [來自上一層], [然後生成並傳遞一個輸出值], [（通常是非線性的）], [到下一層]",
    ],

        [英] [related] [A function], "[和] [関数][kannsuu][かんすう]"[漢] [相關]
        [(for example, ReLU or sigmoid)],  [（たとえば、ReLUまたはシグモイド）],[tatoeba, ReLU matawa sigumoido][たとえば、ReLUまたはシグモイド] [（例如，ReLU 或 sigmoid）]
        [takes in the weighted sum of all of the inputs],  [すべてのインプットの加重和を取る][subeteno inputto no kajuwa wo toru][すべてのインプットのかじゅうわをとる], [獲取所有輸入的加權和]
        [from the previous layer],  [前のレイヤーから],[maeno reiyaa kara][まえのレイヤーから] [來自上一層]
        [and then generates and passes an output value],  [そして出力値を生成して渡す][soshite syutsuryokuchi wo kiseishite watasu][そしてしゅつりょくちをきせいしてわたす], [然後生成並傳遞一個輸出值]
        [(typically nonlinear)], [（通常は非線形）] ,[tsuujou wa hisenkei][つうじょうはひせんけい] [（通常是非線性的）]
        [to the next layer.]", [次のレイヤーへ] ,[tsugi no reiyaa e][つぎのレイヤーへ] [到下一層]",
    ],
