    "what": [
      "A gradient descent algorithm in which the batch size is one. In other words, SGD relies on a single example chosen uniformly at random from a dataset to calculate an estimate of the gradient at each step.",
      "[related] gradient, descent, algorithm, batch size, one, relies on, single example, chosen, uniformly, random, from, dataset, to calculate, estimate, gradient, at each step.",
      "[関連] 強化学習 [pronunciation] [hiragana or katakana], パラメータ値 [pronunciation] [hiragana or katakana], 説明 [pronunciation] [hiragana or katakana], 現在の構成 [pronunciation] [hiragana or katakana], 環境 [pronunciation] [hiragana or katakana], エージェント [pronunciation] [hiragana or katakana], アクションを選択 [pronunciation] [hiragana or katakana]",	    
      "[相關] 梯度, 下降, 算法, 批量大小, 一個, 依賴於單個示例, 選擇, 均勻, 隨機, 來自數據集, 在每一步計算, 估計, 梯度",  
    ],
