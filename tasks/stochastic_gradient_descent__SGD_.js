    "what": [
      "A gradient descent algorithm in which the batch size is one. In other words, SGD relies on a single example chosen uniformly at random from a dataset to calculate an estimate of the gradient at each step.",
      "[英] [related] gradient, descent, algorithm, batch size, one, relies on, single example, chosen, uniformly, random, from, dataset, to calculate, estimate, gradient, at each step.",
      "[和] [関連] gardient 勾配 [Koubai] [こうばい], descent 降下 [Kouka] [こうか], algorithm アルゴリズム [Arugorizumu] [アルゴリズム], batch sizeバッチサイズ [Bacchi saizu] [バッチサイズ], one 1 [ichi] [いち],relies on 依存する [Izon suru] [いぞんする] Single 各ステップで計算 [kaku suteppu de keisan]
[かくステップでけいさん], 推定 [Suitei] [すいてい], 勾配を計算するために [Koubai wo Keisansuru tameni] [こうばいをけいさんするために], データセットから [Deeta setto kara] [データセットから], 選択された単一の例に依存します [Sentaku sareta tannitsu no reini izonshimasu] [せんたくされた　たんいつのれいに　いぞんします]",	    
      "[漢] [相關] 梯度, 下降, 算法, 批量大小, 一個, 依賴於單個示例, 選擇, 均勻, 隨機, 來自數據集, 在每一步計算, 估計, 梯度",  
    ],
